{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between w2v and ELMo on a sentiment task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "We try to reproduce the results obtained in the paper [Evaluation of sentence embeddings in downstream\n",
    "and linguistic probing tasks](https://arxiv.org/pdf/1806.06259.pdf). The goal is to compare the performances of different sentence embeddings.\n",
    "\n",
    "More specifically we will compare:\n",
    "* Average of word2vec vectors\n",
    "* SIF (Smoothing inverse frequency) with w2v vectors\n",
    "* ELMo\n",
    "\n",
    "The classification is done thanks to a one hidden layer perceptron with 50 neurons (as in the article). If enough time perform the classification also with a logistic regression\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow                1.8.0                         0  \n",
      "tensorflow-base           1.8.0            py36h1a1b453_0  \n"
     ]
    }
   ],
   "source": [
    "! conda list | grep tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ac40448\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import adam\n",
    "\n",
    "from keras import backend as K\n",
    "import keras.layers as layers\n",
    "from keras.models import Model, load_model\n",
    "from keras.engine import Layer\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(data_file):\n",
    "    df_out = pd.DataFrame()\n",
    "    df = pd.read_table('data/stsa.binary.train', header=None)\n",
    "    labels = []\n",
    "    sentences = []\n",
    "    for i in range(len(df[0])):\n",
    "        labels.append(int(df[0][i][:1]))\n",
    "        sentences.append(df[0][i][1:])\n",
    "    df_out['X'] = sentences\n",
    "    df_out['Y'] = labels\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_file('data/stsa.binary.train')\n",
    "df_test = read_file('data/stsa.binary.test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w2v + MCP\n",
    "\n",
    "---------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCP:\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = 0.0001\n",
    "        self.batch_size = 32\n",
    "        self.model = self.build_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        init = RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=50, activation='relu', input_dim=self.input_size, kernel_initializer=init))\n",
    "        model.add(Dense(units=self.output_size, activation='softmax', kernel_initializer=init))\n",
    "        \n",
    "        model.compile(loss='mse', optimizer=adam(lr=self.learning_rate), metrics=['accuracy'])\n",
    "        return model\n",
    "        \n",
    "    def train(self, X, Y, n_epochs):\n",
    "        scores = self.model.fit(X,Y, epochs=n_epoches, verbose=1, batch_size=self.batch_size)\n",
    "        loss = scores.history['loss']\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainable elmo\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple test on elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using C:\\Users\\ac40448\\AppData\\Local\\Temp\\tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "embeddings = elmo(\n",
    "[\"the cat is on the mat\", \"dogs are in the fog\", \"pascal jauffret is in the house tonight\"],\n",
    "signature=\"default\",\n",
    "as_dict=True)[\"elmo\"]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    test=embeddings[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "tokens_input = [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"],\n",
    "[\"dogs\", \"are\", \"in\", \"the\", \"fog\", \"\"]]\n",
    "tokens_length = [6, 5]\n",
    "embeddings = elmo(\n",
    "inputs={\n",
    "\"tokens\": tokens_input,\n",
    "\"sequence_len\": tokens_length\n",
    "},\n",
    "signature=\"tokens\",\n",
    "as_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'module_2_apply_tokens/bilm/Reshape_1:0' shape=(2, 6, 512) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['word_emb']."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainable layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmoEmbeddingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dimensions = 1024\n",
    "        self.trainable=True\n",
    "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n",
    "                               name=\"{}_module\".format(self.name))\n",
    "\n",
    "        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
    "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
    "                      as_dict=True,\n",
    "                      signature='default',\n",
    "                      )['default']\n",
    "        return result\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return K.not_equal(inputs, '--PAD--')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1024)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
